#### Module to clear owners .csv and fix city and country codes ####import pandas as pdimport numpy as npimport reimport mathfrom datetime import datetimestartTime = datetime.now()def clean_city(string):	# checks if string isn't null, empty, or any compination of ontario (there are a lot of ontarios cities in the world)	if string != np.nan or string != '' or "Ontario" not in string or "ONTARIO" not in string or "ontario" not in string:		# brings through only letters of city - drops special characters, numbers, etc.		return re.sub(r'[^A-Za-z\ \-]', '', string)	# checks if value is null or empty and then changes to "check" so that these can be manually updated later	else:		string = "check"		return stringdef remove_lead_trail_spaces(x):	# checks if string has leading and trailing spaces and then either removes 	if x == '' or (x[0] != ' ' and x[-1] != ' '):		return x	elif x[0] == ' ' and x[-1] == ' ':		return x[1:-1]	elif x[0] == ' ' and x[-1] != ' ':		return x[1:]	else:		return x[:-1]def clean_owners(df, col):	# returns only letters and spaces except for ontario and replaces city with "check" otherwise 	df[col] = df[col].apply(lambda x: clean_city(x))	# replaces double spaces with single spaces	df[col] = df[col].apply(lambda x: x.replace('  ', ' '))	# removes all leading and trailing spaces from cell	df[col] = df[col].apply(lambda x: remove_lead_trail_spaces(x))	return dfdef df_lookup(df, df_map, col_df, col_df_map):	# creates lookup table of duplicates | there are some duplicates that have duplicates	df_duplicates_w_duplicates = df_map[df_map[col_df_map].duplicated()==True]	# creates list of unique duplicates and deletes first temp dataframe from memory	df_duplicates = df_duplicates_w_duplicates[df_duplicates_w_duplicates[col_df_map].duplicated()==False]	del df_duplicates_w_duplicates	# double checks that all cities are upper case so they can be compared	df_duplicates[col_df_map] = df_duplicates[col_df_map].apply(lambda x: x.upper())	df[col_df] = df[col_df].apply(lambda x: x.upper())	df_map[col_df_map] = df_map[col_df_map].apply(lambda x: x.upper())	# creates column index to use as column number update with .iloc below	print df.columns	col_index = df.columns.get_loc('own_addr_country_cd')	# goes through every row of the table to update the country codes per city	for row in df[col_df]:		# checks to see if row - city - is not in duplicates because we want to avoid replacing duplicate values		if row not in df_duplicates[col_df_map] and df_map[df_map[col_df_map] == row].shape[0] == 1:		# updates country code in base dataframe with the 2 char country code from the lookup table - df_map			row_index = df_map[df_map[col_df_map] == row].index.tolist()[0]			print row_index			df.iloc[row_index:row_index+1, col_index:col_index+1] = df_map[df_map[col_df_map] == row]['iso2']		else:			continue			# row_index = df_map[df_map[col_df_map] == row].index.tolist()			# print row_index			# df.iloc[row_index:row_index+1, col_index:col_index+1] = 'check'	return dfif __name__ == '__main__':	d_owners = {'own_addr_1':str, 'own_addr_2':str, 'own_addr_city':str, 'own_composed_of':str,    'own_addr_country_cd':str, 'own_altn_name':str, 'own_entity_desc':str,    'own_seq':str, 'own_entity_cd':str, 'own_nalty_country_cd':str,    'own_nalty_other_cd':str, 'own_nalty_state_cd':str, 'own_addr_other_cd':str,    'own_name':str, 'own_type_cd':str, 'own_addr_postal':str, 'own_addr_state_cd':str,    'own_id':str, 'serial_no':str}		df_owners = pd.read_csv('../data/owner.csv', dtype=d_owners)	df_owners = df_owners.fillna(value='')	df_city_country = pd.read_csv('../../topo_maps/world_cities_map.csv', index_col=0)	df_owners = clean_owners(df_owners, 'own_addr_city')	df_owners = df_lookup(df_owners, df_city_country, 'own_addr_city', 'city')	pd.to_csv('../data/owners_cities_countries.csv', index=False)	print datetime.now() - startTime	print "Done!"